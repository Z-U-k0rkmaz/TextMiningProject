{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re # regular expressions\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stop_words = set(file.read().splitlines())\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  writer  file_id                                             column\n",
      "0    ttu       27  O zaman 28 Şubat neden yapıldı?  \\r\\n     \\r\\n...\n",
      "1    ttu       28  O zaman 28 Şubat neden yapıldı?  \\r\\n     \\r\\n...\n",
      "2    ttu        3  Cumhuriyetin en kritik yerel seçimi \\r\\nMURAT ...\n",
      "3    ttu        4  Çekilin artık kamera karşısından \\r\\nHER kar y...\n",
      "4    ttu       23  Lorant'ın heyecan veren hedefi  \\r\\n     \\r\\n\\...\n",
      "5    ttu       14  Gerçekten de gülüp geçilecek bir öneri \\r\\nGAZ...\n",
      "6    ttu       13  Mercedes çeşitlemeleri \\r\\nTÜRK insanı, Merced...\n",
      "7    ttu       31  Yazarın çilesi  \\r\\n     \\r\\n\\r\\n  \\r\\nZAMAN z...\n",
      "8    ttu       19  Tüm yazı konularını silip süpüren fotoğraf \\r\\...\n",
      "9    ttu       11  Şarkta böyledir bu işler...  \\r\\n     \\r\\nttu...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 630 entries, 0 to 629\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   writer   630 non-null    object\n",
      " 1   file_id  630 non-null    int64 \n",
      " 2   column   630 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 14.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_json(\"dataset\\Turkish_data_depository_630koseyazisi.jsonl\",lines=True)\n",
    "print(dataset.head(10))\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type x : <class 'numpy.ndarray'> , type y : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = dataset.iloc[:, 2].values.astype(\"str\") # author text\n",
    "y = dataset.iloc[:, 0].values.astype(\"str\") # author name\n",
    "\n",
    "print(f\"type x : {type(x)} , type y : {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turkish stop words\n",
    "stop_words = load_stop_words(\"stopwordsTR\\stopwords.txt\")\n",
    "\n",
    "# Her bir metni temizleme işlemi\n",
    "for i in range(len(x)):\n",
    "    # Convert to lowercase - Küçük harfe çevirme\n",
    "    x[i] = x[i].lower()\n",
    "    \n",
    "    # Remove escape characters - Kaçış karakterlerini kaldırma\n",
    "    x[i] = re.sub(r'[\\r\\n]', ' ', x[i]) \n",
    "    \n",
    "    # Remove unnecessary characters - Gereksiz karakterleri kaldırma\n",
    "    x[i] = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', x[i])\n",
    "    \n",
    "    # Remove stop words - Stop kelimeleri kaldırma\n",
    "    x[i] = ' '.join([word for word in x[i].split() if word not in stop_words])\n",
    "    \n",
    "    # Remove punctuation marks - Noktalama işaretlerini kaldırma\n",
    "    x[i] = x[i].translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove repeating spaces - Tekrar eden boşlukları kaldırma\n",
    "    x[i] = re.sub(r'\\s+', ' ', x[i])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
