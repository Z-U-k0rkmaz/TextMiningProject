{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re # regular expressions\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stop_words = set(file.read().splitlines())\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  writer  file_id                                             column\n",
      "0    ttu       27  O zaman 28 Şubat neden yapıldı?  \\r\\n     \\r\\n...\n",
      "1    ttu       28  O zaman 28 Şubat neden yapıldı?  \\r\\n     \\r\\n...\n",
      "2    ttu        3  Cumhuriyetin en kritik yerel seçimi \\r\\nMURAT ...\n",
      "3    ttu        4  Çekilin artık kamera karşısından \\r\\nHER kar y...\n",
      "4    ttu       23  Lorant'ın heyecan veren hedefi  \\r\\n     \\r\\n\\...\n",
      "5    ttu       14  Gerçekten de gülüp geçilecek bir öneri \\r\\nGAZ...\n",
      "6    ttu       13  Mercedes çeşitlemeleri \\r\\nTÜRK insanı, Merced...\n",
      "7    ttu       31  Yazarın çilesi  \\r\\n     \\r\\n\\r\\n  \\r\\nZAMAN z...\n",
      "8    ttu       19  Tüm yazı konularını silip süpüren fotoğraf \\r\\...\n",
      "9    ttu       11  Şarkta böyledir bu işler...  \\r\\n     \\r\\nttu...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 630 entries, 0 to 629\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   writer   630 non-null    object\n",
      " 1   file_id  630 non-null    int64 \n",
      " 2   column   630 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 14.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_json(\"dataset\\Turkish_data_depository_630koseyazisi.jsonl\",lines=True)\n",
    "print(dataset.head(10))\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type x : <class 'numpy.ndarray'> , type y : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = dataset.iloc[:, 2].values.astype(\"str\") # author text\n",
    "y = dataset.iloc[:, 0].values.astype(\"str\") # author name\n",
    "\n",
    "print(f\"type x : {type(x)} , type y : {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turkish stop words\n",
    "stop_words = load_stop_words(\"stopwordsTR\\stopwords.txt\")\n",
    "\n",
    "# Her bir metni temizleme işlemi\n",
    "for i in range(len(x)):\n",
    "    # Convert to lowercase - Küçük harfe çevirme\n",
    "    x[i] = x[i].lower()\n",
    "    \n",
    "    # Remove escape characters - Kaçış karakterlerini kaldırma\n",
    "    x[i] = re.sub(r'[\\r\\n]', ' ', x[i]) \n",
    "    \n",
    "    # Remove unnecessary characters - Gereksiz karakterleri kaldırma\n",
    "    x[i] = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', x[i])\n",
    "    \n",
    "    # Remove stop words - Stop kelimeleri kaldırma\n",
    "    x[i] = ' '.join([word for word in x[i].split() if word not in stop_words])\n",
    "    \n",
    "    # Remove punctuation marks - Noktalama işaretlerini kaldırma\n",
    "    x[i] = x[i].translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove repeating spaces - Tekrar eden boşlukları kaldırma\n",
    "    x[i] = re.sub(r'\\s+', ' ', x[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "It is a statistical method used to measure the importance of words in text documents. TF-IDF vectors combine each word's frequency (TF) in the text and its rarity (IDF) across all documents.\n",
    "\n",
    "Metin belgelerindeki kelimelerin önemini ölçmek için kullanılan bir istatistiksel yöntemdir. TF-IDF vektörleri, her kelimenin metindeki sıklığını (TF) ve tüm belgelerdeki nadirliğini (IDF) birleştirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings (Kelime Gömme):\n",
    "It represents words with numerical vectors using word embedding models with techniques such as Word2Vec, GloVe, FastText. These vectors better reflect the meaning of the word.\n",
    "\n",
    "Word2Vec, GloVe, FastText gibi tekniklerle kelime gömme modelleri kullanarak kelimeleri sayısal vektörlerle temsil eder. Bu vektörler, kelimenin anlamını daha iyi yansıtır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW (Bag of Words):\n",
    "It creates a vector that represents the presence of words in the text. BoW vectors use a frequency-based approach to represent the presence or absence of each word.\n",
    "\n",
    "Metinde geçen kelimelerin varlığını temsil eden bir vektör oluşturur. BoW vektörleri, her bir kelimenin varlığını veya yokluğunu temsil eden sıklık tabanlı bir yaklaşım kullanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Approach(N-gram Yaklaşımı):\n",
    "It creates feature vectors by taking into account consecutive word groups of the text.\n",
    "\n",
    "Metnin ardışık kelime gruplarını dikkate alarak özellik vektörleri oluşturur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
