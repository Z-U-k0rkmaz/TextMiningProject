{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import re # regular expressions\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stop_words = set(file.read().splitlines())\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(\"dataset\\Turkish_data_depository_630koseyazisi.jsonl\",lines=True)\n",
    "print(dataset.head(10))\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, 2].values.astype(\"str\") # author text\n",
    "y = dataset.iloc[:, 0].values.astype(\"str\") # author name\n",
    "\n",
    "print(f\"type x : {type(x)} , type y : {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turkish stop words\n",
    "stop_words = load_stop_words(\"stopwordsTR\\stopwords.txt\")\n",
    "\n",
    "# Her bir metni temizleme işlemi\n",
    "for i in range(len(x)):\n",
    "    # Convert to lowercase - Küçük harfe çevirme\n",
    "    x[i] = x[i].lower()\n",
    "    \n",
    "    # Remove escape characters - Kaçış karakterlerini kaldırma\n",
    "    x[i] = re.sub(r'[\\r\\n]', ' ', x[i]) \n",
    "    \n",
    "    # Remove unnecessary characters - Gereksiz karakterleri kaldırma\n",
    "    x[i] = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', x[i])\n",
    "    \n",
    "    # Remove stop words - Stop kelimeleri kaldırma\n",
    "    x[i] = ' '.join([word for word in x[i].split() if word not in stop_words])\n",
    "    \n",
    "    # Remove punctuation marks - Noktalama işaretlerini kaldırma\n",
    "    x[i] = x[i].translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove repeating spaces - Tekrar eden boşlukları kaldırma\n",
    "    x[i] = re.sub(r'\\s+', ' ', x[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "It is a statistical method used to measure the importance of words in text documents. TF-IDF vectors combine each word's frequency (TF) in the text and its rarity (IDF) across all documents.\n",
    "\n",
    "Metin belgelerindeki kelimelerin önemini ölçmek için kullanılan bir istatistiksel yöntemdir. TF-IDF vektörleri, her kelimenin metindeki sıklığını (TF) ve tüm belgelerdeki nadirliğini (IDF) birleştirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vector - TF-IDF vektörlerini oluşturma\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(x)\n",
    "\n",
    "example_tfidf_vector = tfidf_matrix[0]\n",
    "print(\"TF-IDF Vektörü (Örnek):\", example_tfidf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings (Kelime Gömme):\n",
    "It represents words with numerical vectors using word embedding models with techniques such as Word2Vec, GloVe, FastText. These vectors better reflect the meaning of the word.\n",
    "\n",
    "Word2Vec, GloVe, FastText gibi tekniklerle kelime gömme modelleri kullanarak kelimeleri sayısal vektörlerle temsil eder. Bu vektörler, kelimenin anlamını daha iyi yansıtır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BoW vector - BoW vektörlerini oluşturma\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(x)\n",
    "\n",
    "example_bow_vector = bow_matrix[0]\n",
    "print(\"BoW Vektörü (Örnek):\", example_bow_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Approach(N-gram Yaklaşımı):\n",
    "It creates feature vectors by taking into account consecutive word groups of the text.\n",
    "\n",
    "Metnin ardışık kelime gruplarını dikkate alarak özellik vektörleri oluşturur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create Trigram BoW vector - Trigram BoW vektörlerini oluşturma\n",
    "trigram_vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "trigram_matrix = trigram_vectorizer.fit_transform(x)\n",
    "\n",
    "example_trigram_vector = trigram_matrix[0]\n",
    "print(\"Trigram BoW Vektörü (Örnek):\", example_trigram_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW (Bag of Words) Vektörleri ile Karar Ağacı (Decision Tree) Modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verileri eğitim ve test setlerine ayırma\n",
    "x_train, x_test, y_train, y_test = train_test_split(bow_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Karar Ağacı modelini oluşturma ve eğitme\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# Test seti üzerinde modelin performansını değerlendirme\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Karar Ağacı Modeli Doğruluğu:\", accuracy)\n",
    "\n",
    "# Karar Ağacı modelinin performansını görselleştirme\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.show()\n",
    "\n",
    "# Sınıflandırma raporunu görüntüleme\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vektörleri ile Destek Vektör Makinesi (Support Vector Machine - SVM) Modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verileri eğitim ve test setlerine ayırma\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Destek Vektör Makinesi (SVM) modelini oluşturma ve eğitme\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "# Test seti üzerinde modelin performansını değerlendirme\n",
    "y_pred = svm_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Modeli Doğruluğu:\", accuracy)\n",
    "\n",
    "# karar ağacı modelinin performansını görselleştirme\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.show()\n",
    "\n",
    "# Sınıflandırma raporunu görüntüleme\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram BoW Vektörleri ile Naive Bayes Modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verileri eğitim ve test setlerine ayırma\n",
    "x_train, x_test, y_train, y_test = train_test_split(trigram_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Naive Bayes modelini oluşturma ve eğitme\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(x_train, y_train)\n",
    "\n",
    "# Test seti üzerinde modelin performansını değerlendirme\n",
    "y_pred = naive_bayes.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Naive Bayes Modeli Doğruluğu:\", accuracy)\n",
    "\n",
    "# naive bayes modelinin performansını görselleştirme\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.show()\n",
    "\n",
    "# Sınıflandırma raporunu görüntüleme\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(bow_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rnd_forest = RandomForestClassifier()\n",
    "rnd_forest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rnd_forest.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Modeli Doğruluğu:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.show()\n",
    "\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "print(classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(bow_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Modeli Doğruluğu:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(bow_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "gradient_boosting.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gradient_boosting.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Gradient Boosting Modeli Doğruluğu:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
